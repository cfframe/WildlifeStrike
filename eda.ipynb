{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d39f15d",
   "metadata": {},
   "source": [
    "# EDA for FAA data\n",
    "Original download is an Excel file.\n",
    "Typical running times:\n",
    "- from scratch: ~ 8 mins if not saving to Excel\n",
    "- from uploaded gzip file: < 1 min if not saving to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bb4451",
   "metadata": {},
   "outputs": [],
   "source": [
    "must_save_final_to_excel = False  # True adds about 8 minutes to runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e228104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import datetime, date, timedelta\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "start_time = datetime.now()\n",
    "print (f'Start: {start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff33c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If Output/df_main1.parquet.gzip exists, load that otherwise load from Excel\n",
    "raw_data_file_path = 'Data/Wildlife strike data.xlsx'\n",
    "parquet_file_path = 'Output/df_main1.parquet.gzip'\n",
    "is_data_loaded_from_Excel = False\n",
    "try:\n",
    "    # Takes less than 1 second to read in approx 30MB of 327K rows\n",
    "    df_main = pd.read_parquet(parquet_file_path)\n",
    "    print(f'Loaded cleaned data from {parquet_file_path}')\n",
    "except FileNotFoundError:\n",
    "    # Takes 6 to 7 minutes to read in approx 140MB of 327K rows\n",
    "    is_data_loaded_from_Excel = True\n",
    "    df_main = pd.read_excel(raw_data_file_path, sheet_name='Sheet1', dtype=str)\n",
    "    print(f'Loaded raw data from {raw_data_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f994159",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_data_loaded_from_Excel:\n",
    "    # Numeric columns\n",
    "    df_main.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0c2ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-numeric columns\n",
    "if is_data_loaded_from_Excel:\n",
    "    df_main.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16136bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_data_loaded_from_Excel:\n",
    "    df_main.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a146e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_data_loaded_from_Excel:\n",
    "    # Drop columns of no interest\n",
    "    drop_cols = ['RUNWAY', 'LOCATION', 'OPID', 'REG', 'FLT', 'AMA', 'AMO', 'EMA', 'EMO', 'ENG_1_POS', 'ENG_2_POS', 'ENG_3_POS', 'ENG_4_POS', 'AOS', \n",
    "                'COST_REPAIRS', 'COST_OTHER', 'COST_REPAIRS_INFL_ADJ', 'COST_OTHER_INFL_ADJ', 'INGESTED_OTHER', 'STR_OTHER', 'DAM_OTHER', \n",
    "                'OTHER_SPECIFY', 'EFFECT_OTHER', 'BIRD_BAND_NUMBER', 'SPECIES_ID',\n",
    "                'REMARKS', 'ENROUTE_STATE', 'NR_INJURIES', 'NR_FATALITIES', 'COMMENTS', 'REPORTED_NAME', 'REPORTED_TITLE',\n",
    "                'SOURCE', 'PERSON', 'LUPDATE', 'TRANSFER'\n",
    "    ]\n",
    "    for col in drop_cols:\n",
    "        if col in df_main.columns:\n",
    "            df_main.drop(columns=[col], inplace=True)\n",
    "\n",
    "    df_main.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644f0643",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_data_loaded_from_Excel:\n",
    "    df_main.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753af02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_data_loaded_from_Excel:\n",
    "    df_main.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa4fabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_data_loaded_from_Excel:\n",
    "    # Drop rows with non-numeric LATITUDE or LONGITUDE\n",
    "    df_main = df_main[pd.to_numeric(df_main['AIRPORT_LATITUDE'], errors='coerce').notnull()]\n",
    "    df_main = df_main[pd.to_numeric(df_main['AIRPORT_LONGITUDE'], errors='coerce').notnull()]\n",
    "    # Convert NUM_SEEN and NUM_STRUCK to strings\n",
    "    df_main['NUM_SEEN'] = df_main['NUM_SEEN'].astype(str)\n",
    "    df_main['NUM_STRUCK'] = df_main['NUM_STRUCK'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd95156",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_data_loaded_from_Excel:\n",
    "    # Find columns with inconsistent data types. Ignore columns with all numeric or all non-numeric values. \n",
    "    # Ignore columns with mixed types but no numeric values. Ignore columns with missing values but otherwise consistent types.\n",
    "    # Get counts of different types vs columns.\n",
    "    type_counts = {}\n",
    "    for col in df_main.columns:\n",
    "        types = df_main[col].apply(lambda x: type(x)).value_counts()\n",
    "        if len(types) > 1 and not (types.index.isin([int, float]).all() or types.index.isin([str]).all() or (types.index.isin([str, type(None)]).all()) or (types.index.isin([int, float, type(None)]).all())):\n",
    "            type_counts[col] = types\n",
    "    type_counts_df = pd.DataFrame(type_counts).fillna(0).astype(int)\n",
    "\n",
    "    # Transpose for display purposes.\n",
    "    type_counts_df = type_counts_df.T\n",
    "\n",
    "    print(type_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3d7e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_data_loaded_from_Excel:\n",
    "    # Identify columns with missing values. Give counts and percentages to 1 decimal place.\n",
    "    missing_counts = df_main.isnull().sum()\n",
    "    missing_percent = ( missing_counts / len(df_main) * 100 ).round(1)\n",
    "    missing_df = pd.DataFrame({'Missing Count': missing_counts, 'Missing Percent': missing_percent})\n",
    "    missing_df = missing_df[missing_df['Missing Count'] > 0]\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da023a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_data_loaded_from_Excel:\n",
    "    # Remove columns with more than 50% missing values\n",
    "    cols_to_drop = missing_df[missing_df['Missing Percent'] > 50].index\n",
    "    df_main.drop(columns=cols_to_drop, inplace=True)\n",
    "    print(f'Dropped columns with > 50% missing values: {list(cols_to_drop)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a571799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final checks of data (place all other data cleaning above this line)\n",
    "# Check 1/3\n",
    "df_main.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c6e3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check 2/3\n",
    "df_main.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab9d199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check 3/3\n",
    "df_main.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cb2260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set integer columns to integer data types\n",
    "int_columns = ['INDEX_NR', 'INCIDENT_MONTH', 'INCIDENT_YEAR', 'AC_MASS', 'NUM_ENGS', 'NR_INJURIES', 'NR_FATALITIES']\n",
    "for col in int_columns:\n",
    "    if col in df_main.columns:\n",
    "        df_main[col] = df_main[col].astype('Int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afa9e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path_1 = 'Output/df_main1.parquet.gzip'\n",
    "\n",
    "if is_data_loaded_from_Excel:\n",
    "    df_main.to_parquet(output_path_1, compression='gzip')\n",
    "# print current time and elapsed time\n",
    "end_time = datetime.now()\n",
    "# Print output path\n",
    "print(f'Cleaned data saved to {output_path_1}\\n')\n",
    "\n",
    "print(\n",
    "    f'Load, clean and save data end: {datetime.strftime(end_time, \"%H:%M:%S\")},'\n",
    "    + f' Elapsed time: {str(end_time - start_time).split(\".\")[0]}'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1237347",
   "metadata": {},
   "source": [
    "## Add derived columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd93571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an index column based on FAAREGION, call it FAAREGION_INDEX\n",
    "if 'FAAREGION' in df_main.columns:\n",
    "    df_main['FAAREGION'] = df_main['FAAREGION'].astype(str).str.strip()\n",
    "    faa_region_mapping = {region: idx for idx, region in enumerate(sorted(df_main['FAAREGION'].unique()), start=0)}\n",
    "    df_main['FAAREGION_INDEX'] = df_main['FAAREGION'].map(faa_region_mapping).astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d66121b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split day into half-hour periods. Time is given as HH:MM. Ignore missing values\n",
    "def split_time_to_half_hour_periods(time_str):\n",
    "    if pd.isna(time_str):\n",
    "        return np.nan\n",
    "    try:\n",
    "        time_obj = datetime.strptime(time_str, '%H:%M')\n",
    "        hour = time_obj.hour\n",
    "        minute = time_obj.minute\n",
    "        if minute < 30:\n",
    "            return f'{hour:02d}:00-{hour:02d}:29'\n",
    "        else:\n",
    "            # next_hour = (hour + 1) % 24\n",
    "            return f'{hour:02d}:30-{hour:02d}:59'\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "df_main['TIME_PERIOD'] = df_main['TIME'].apply(split_time_to_half_hour_periods)\n",
    "# Check TIME_PERIOD\n",
    "df_main['TIME_PERIOD'].value_counts(dropna=False).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db76054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a time period index to each half-hour period\n",
    "def time_period_index(time_period_str):\n",
    "    if pd.isna(time_period_str):\n",
    "        return np.nan\n",
    "    try:\n",
    "        start_time = time_period_str.split('-')[0]\n",
    "        hour, minute = map(int, start_time.split(':'))\n",
    "        return hour * 2 + (1 if minute >= 30 else 0)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "df_main['TIME_PERIOD_INDEX'] = df_main['TIME_PERIOD'].apply(time_period_index)\n",
    "# Check TIME_PERIOD_INDEX\n",
    "df_main['TIME_PERIOD_INDEX'].value_counts(dropna=False).sort_index()\n",
    "df_main['TIME_PERIOD_INDEX'] = df_main['TIME_PERIOD_INDEX'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9f5124",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main['INCIDENT_HOUR'] = df_main['TIME'].apply(lambda x: x.split(':')[0] if ':' in str(x) else np.nan).astype('Int64')\n",
    "df_main['INCIDENT_MINUTE'] = df_main['TIME'].apply(lambda x: x.split(':')[1] if ':' in str(x) else np.nan).astype('Int64')\n",
    "df_main['INCIDENT_HALF_HOUR'] = df_main.apply(lambda row:\n",
    "    f\"{int(row['INCIDENT_HOUR']):02d}:{'00' if row['INCIDENT_MINUTE'] < 30 else '30'}\" \n",
    "        if pd.notnull(row['INCIDENT_HOUR']) and pd.notnull(row['INCIDENT_MINUTE']) \n",
    "        else np.nan,\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f677d624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive abbreviated month name from INCIDENT_MONTH\n",
    "month_names = {1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun', \n",
    "               7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'}\n",
    "\n",
    "df_main['INCIDENT_MONTH_NAME'] = df_main['INCIDENT_MONTH'].apply(lambda x: month_names.get(x) if pd.notnull(x) else np.nan)\n",
    "# Check INCIDENT_MONTH_NAME, sort by month number\n",
    "df_main[['INCIDENT_MONTH', 'INCIDENT_MONTH_NAME']].drop_duplicates().sort_values(by='INCIDENT_MONTH')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26914c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign day of year to INCIDENT_DATE\n",
    "df_main['INCIDENT_DAY_OF_YEAR'] = pd.to_datetime(df_main['INCIDENT_DATE'], errors='coerce').dt.dayofyear.astype('Int64')\n",
    "print(df_main['INCIDENT_DAY_OF_YEAR'].max())\n",
    "# # Decrement INCIDENT_DAY_OF_YEAR when INCIDENT_DATE is after 29th February and year is a leap year\n",
    "# df_main['INCIDENT_DAY_OF_YEAR'] = df_main.apply(lambda row: row['INCIDENT_DAY_OF_YEAR'] - 1\n",
    "#                                                 if pd.notnull(row['INCIDENT_DAY_OF_YEAR']) and\n",
    "#                                                    pd.notnull(row['INCIDENT_YEAR']) and\n",
    "#                                                    row['INCIDENT_YEAR'] % 4 == 0 and\n",
    "#                                                    row['INCIDENT_DAY_OF_YEAR'] > 59\n",
    "#                                                 else row['INCIDENT_DAY_OF_YEAR'], axis=1)\n",
    "# print(df_main['INCIDENT_DAY_OF_YEAR'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09da4e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change FAAREGION column name to FAA Region and all other column names to Title Case with spaces instead of underscores\n",
    "df_main.columns = [col.replace('_', ' ').title() for col in df_main.columns]\n",
    "df_main.rename(columns={'Faaregion': 'FAA Region', 'Faaregion Index': 'FAA Region Index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a02657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned and prepared data as Parquet gzip\n",
    "output_path_2_parquet = 'Output/df_main2.parquet.gzip'\n",
    "df_main.to_parquet(output_path_2_parquet, compression='gzip')\n",
    "# Print output path\n",
    "print(f'{datetime.strftime(datetime.now(), \"%H:%M:%S\")} Additional data saved to {output_path_2_parquet}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc091768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned and prepared data as csv\n",
    "output_path_2_csv = 'Output/Wildlife Cleaned.csv'\n",
    "df_main.to_csv(output_path_2_csv, index=False)\n",
    "# Print output path\n",
    "print(f'{datetime.strftime(datetime.now(), \"%H:%M:%S\")} Additional data saved to {output_path_2_csv}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51243d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned and prepared data as Excel\n",
    "if must_save_final_to_excel:\n",
    "    # This step takes circa 8 mins for 327K rows\n",
    "    output_path_2_excel = 'Output/Wildlife Cleaned.xlsx'\n",
    "    df_main.to_excel(output_path_2_excel, index=False)\n",
    "    # Print output path\n",
    "    print(f'{datetime.strftime(datetime.now(), \"%H:%M:%S\")} Additional data saved to {output_path_2_excel}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa07f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print current time and elapsed time\n",
    "end_time = datetime.now()\n",
    "print(\n",
    "    f'Save cleaned and prepared data end: {datetime.strftime(end_time, \"%H:%M:%S\")},'\n",
    "    + f' Elapsed time: {str(end_time - start_time).split(\".\")[0]}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392ac499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure columns\n",
    "measure_cols = ['INCIDENT_MONTH', 'AC_MASS', 'NUM_ENGS', 'HEIGHT', 'TIME_PERIOD_INDEX']\n",
    "# Make column names Title Case with spaces instead of underscores\n",
    "measure_cols = [col.replace('_', ' ').title() for col in measure_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54c9b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "sns.heatmap(df_main[measure_cols].corr(), vmax=0.6, square=True, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c72122c",
   "metadata": {},
   "source": [
    "AC_MASS and NUM_ENGS:\n",
    "- no surprise here - the bigger the aircraft, the more engines it is likely to have. Slightly surprised the correlation is not stronger\n",
    "\n",
    "Everything else:\n",
    "- uncorrelated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a094ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(measure_cols):\n",
    "    if pd.api.types.is_numeric_dtype(df_main[col]):\n",
    "        q1 = df_main[col].quantile(0.25)\n",
    "        q3 = df_main[col].quantile(0.75)\n",
    "        \n",
    "        sns.histplot(df_main[col], kde=True, ax=axes[i], color='skyblue', edgecolor='black')\n",
    "        axes[i].axvline(q1, color='red', linestyle='--', label=f'Q1 (25%): {q1:.2f}')\n",
    "        axes[i].axvline(q3, color='green', linestyle='--', label=f'Q3 (75%): {q3:.2f}')\n",
    "        axes[i].legend()\n",
    "        \n",
    "    else:\n",
    "        sns.countplot(\n",
    "            data=df_main, \n",
    "            x=col, \n",
    "            hue=col,       \n",
    "            ax=axes[i], \n",
    "            palette='cool', \n",
    "            edgecolor='black', \n",
    "            legend=False   \n",
    "        )   \n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "    axes[i].set_title(f'Distribution of {col}', fontsize=14)\n",
    "    axes[i].set_xlabel(col, fontsize=12)\n",
    "    axes[i].set_ylabel('Frequency', fontsize=12)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44c0938",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = datetime.now()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print (f\"Elapsed from start: {str(elapsed_time).split('.')[0]}; Time: {datetime.now().strftime(format='%Y-%m-%d %H:%M:%S')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
